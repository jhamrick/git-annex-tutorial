{
 "metadata": {
  "name": "",
  "signature": "sha256:27f50d52da5745afbedc576e0aeb05988f48ea6f1d18e2c64b79bab5688575da"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "\n",
      "# clean up existing demo stuff, if it exists\n",
      "if [ -d /tmp/myrepo.git ]; then\n",
      "    rm -rf /tmp/myrepo.git\n",
      "fi\n",
      "if [ -d myrepo ]; then\n",
      "    chmod -R u+w myrepo\n",
      "    rm -rf myrepo\n",
      "fi\n",
      "if [ -d /tmp/external ]; then\n",
      "    chmod -R u+w /tmp/external\n",
      "    rm -rf /tmp/external\n",
      "fi\n",
      "if [ -d /tmp/myrepo-rsync ]; then\n",
      "    chmod -R u+w /tmp/myrepo-rsync\n",
      "    rm -rf /tmp/myrepo-rsync\n",
      "fi"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Tutorial on git-annex"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`git-annex` is an incredibly useful tool for keeping track of your data, without having to actually add it to your git repository. Why would you want this?\n",
      "\n",
      "1. Your data is medium to large (probably >10MB you don't want to add to the git repository)\n",
      "2. Your data is contains sensitive information that you don't want to keep in version control\n",
      "\n",
      "In this tutorial, I'll go over how I use `git-annex` in my workflow, and how you can get started using it, too! For more details, you can check out the `git-annex` website: [https://git-annex.branchable.com/](https://git-annex.branchable.com/). In particular, the [walkthrough](https://git-annex.branchable.com/walkthrough/) is a great place to start."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "## Setting up the repository"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, let's just create an empty toy repository. One thing to note is that you *must* have an additional place to store your data that is not GitHub, because GitHub is not going to host tons of data for you for free. I personally store my data in three locations:\n",
      "\n",
      "1. Lab server #1\n",
      "2. Lab server #2\n",
      "3. External hard drive attached to lab server #1\n",
      "\n",
      "For this tutorial, we're just going to store data in temporary directories locally."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, we need to create an empty remote repository -- you can think of this repository as essentially an imitation of what GitHub does:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "\n",
      "# create an empty remote repository\n",
      "mkdir /tmp/myrepo.git\n",
      "cd /tmp/myrepo.git\n",
      "git init --bare"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initialized empty Git repository in /private/tmp/myrepo.git/\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we clone from the remote repository to this directory:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!git clone /tmp/myrepo.git"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Cloning into 'myrepo'...\r\n",
        "warning: You appear to have cloned an empty repository.\r\n",
        "done.\r\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since the repository is empty, let's add a simple README file to it, and then push to the remote:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file myrepo/README.md\n",
      "\n",
      "This is the readme for my repository!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing myrepo/README.md\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "\n",
      "# add the readme to the repository\n",
      "cd myrepo\n",
      "git add README.md\n",
      "git commit -m \"Add README.md\"\n",
      "git push"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[master (root-commit) 78af780] Add README.md\n",
        " 1 file changed, 2 insertions(+)\n",
        " create mode 100644 README.md\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "To /tmp/myrepo.git\n",
        " * [new branch]      master -> master\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "## Dealing with large data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's say that we now have a big datafile that we want to keep track of. We'll simulate this just by creating a big NumPy file filled with random values:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create a big data file\n",
      "import numpy as np\n",
      "bigfile = np.random.rand(1000, 10000)\n",
      "np.save(\"myrepo/bigfile.npy\", bigfile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we take a look at the files in `myrepo`, we'll see that the big file is not gigantic, but probably larger than what we want to store in version control:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls -lha myrepo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total 156264\r\n",
        "drwxr-xr-x   5 jhamrick  staff   170B Dec 12 16:48 \u001b[34m.\u001b[m\u001b[m\r\n",
        "drwxr-xr-x   8 jhamrick  staff   272B Dec 12 16:48 \u001b[34m..\u001b[m\u001b[m\r\n",
        "drwxr-xr-x  12 jhamrick  staff   408B Dec 12 16:48 \u001b[34m.git\u001b[m\u001b[m\r\n",
        "-rw-r--r--   1 jhamrick  staff    38B Dec 12 16:48 README.md\r\n",
        "-rw-r--r--   1 jhamrick  staff    76M Dec 12 16:48 bigfile.npy\r\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We don't want to add this file to the git repository, because git doesn't handle large repositories very well. Moreover, `bigfile.npy` is a binary file, so we won't be able to version it very well, anyway. If we had it in version control, and then ever wanted to make any changes to the file, we'd have to save essentially two full copies of the file, because diffs don't work on binary files."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The solution: `git-annex`!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "## Setting up `git-annex`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To get started with `git-annex`, we need to initialize the repository to be a `git-annex`-compatible repository:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd myrepo && git annex init \"laptop\" # you can use whatever name you want, here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "init laptop "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ok\r\n",
        "(Recording state in git...)\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we can add our big file using `git annex add`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd myrepo && git annex add bigfile.npy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "add bigfile.npy "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ok\r\n",
        "(Recording state in git...)\r\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, if we take a look at what's in `myrepo`, you'll see that the contents of `bigfile.npy` have been moved to a file with a special name in the `.git` folder. The `bigfile.npy` file itself has been turned into a symlink that points to this file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls -lha myrepo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total 16\r\n",
        "drwxr-xr-x   5 jhamrick  staff   170B Dec 12 16:48 \u001b[34m.\u001b[m\u001b[m\r\n",
        "drwxr-xr-x   8 jhamrick  staff   272B Dec 12 16:48 \u001b[34m..\u001b[m\u001b[m\r\n",
        "drwxr-xr-x  13 jhamrick  staff   442B Dec 12 16:48 \u001b[34m.git\u001b[m\u001b[m\r\n",
        "-rw-r--r--   1 jhamrick  staff    38B Dec 12 16:48 README.md\r\n",
        "lrwxr-xr-x   1 jhamrick  staff   200B Dec 12 16:48 \u001b[35mbigfile.npy\u001b[m\u001b[m -> .git/annex/objects/wp/3j/SHA256E-s80000080--68df193c08a87b39d02f5fb271557a36dd1a9af7b9a7f1d0bd0011e7ec253ebd.npy/SHA256E-s80000080--68df193c08a87b39d02f5fb271557a36dd1a9af7b9a7f1d0bd0011e7ec253ebd.npy\r\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we check `git status`, we'll see that this file has been added to the git repository (but not committed yet):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd myrepo && git status"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "On branch master\r\n",
        "Your branch is up-to-date with 'origin/master'.\r\n",
        "Changes to be committed:\r\n",
        "  (use \"git reset HEAD <file>...\" to unstage)\r\n",
        "\r\n",
        "\t\u001b[32mnew file:   bigfile.npy\u001b[m\r\n",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What is being tracked is *not* the full contents of bigfile, but just a symlink to the contents. `git-annex` knows how to keep track of the contents; `git` only knows about the symlink.\n",
      "\n",
      "Let's go ahead and make the commit:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "\n",
      "cd myrepo\n",
      "git commit -m \"Add bigfile.npy\"\n",
      "git push"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[master 55e47fc] Add bigfile.npy\n",
        " 1 file changed, 1 insertion(+)\n",
        " create mode 120000 bigfile.npy\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "To /tmp/myrepo.git\n",
        "   78af780..55e47fc  master -> master\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "## Modifying files in `git-annex`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`git-annex` is paranoid: it tries really hard to make sure you don't lose your data, once you've added it. For example, if we try to overwrite the file, we'll find that it's read-only:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigfile2 = np.random.rand(1000, 10000)\n",
      "np.save(\"myrepo/bigfile.npy\", bigfile2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "[Errno 13] Permission denied: 'myrepo/bigfile.npy'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-13-133cadbc387c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbigfile2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"myrepo/bigfile.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbigfile2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/Users/jhamrick/.virtualenvs/ipython-2.3/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIOError\u001b[0m: [Errno 13] Permission denied: 'myrepo/bigfile.npy'"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Because the contents of `bigfile.npy` aren't actually under version control, if we were able to overwrite the file, we would not be able to undo those changes. So, `git-annex` makes the contents of the file read-only, so you have to be really sure if you want to actually change them, by using `git annex unlock`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd myrepo && git annex unlock bigfile.npy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "unlock bigfile.npy (copying...) "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ok\r\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll see that the symlink no longer exists:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls -lha myrepo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total 156264\r\n",
        "drwxr-xr-x   5 jhamrick  staff   170B Dec 12 16:48 \u001b[34m.\u001b[m\u001b[m\r\n",
        "drwxr-xr-x   8 jhamrick  staff   272B Dec 12 16:48 \u001b[34m..\u001b[m\u001b[m\r\n",
        "drwxr-xr-x  13 jhamrick  staff   442B Dec 12 16:48 \u001b[34m.git\u001b[m\u001b[m\r\n",
        "-rw-r--r--   1 jhamrick  staff    38B Dec 12 16:48 README.md\r\n",
        "-rw-r--r--   1 jhamrick  staff    76M Dec 12 16:48 bigfile.npy\r\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we can try to make the changes to the file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigfile2 = np.random.rand(1000, 10000)\n",
      "np.save(\"myrepo/bigfile.npy\", bigfile2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To tell `git-annex` about the changes, we just need to use `git annex add` again -- similar to how git normally works:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "\n",
      "cd myrepo\n",
      "git annex add bigfile.npy\n",
      "git commit -m \"Update bigfile.npy\"\n",
      "git push"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "add bigfile.npy ok\n",
        "(Recording state in git...)\n",
        "[master 2063b55] Update bigfile.npy\n",
        " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "To /tmp/myrepo.git\n",
        "   55e47fc..2063b55  master -> master\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll see that `bigfile.npy` has gone back to being a symlink:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls -lha myrepo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total 16\r\n",
        "drwxr-xr-x   5 jhamrick  staff   170B Dec 12 16:48 \u001b[34m.\u001b[m\u001b[m\r\n",
        "drwxr-xr-x   8 jhamrick  staff   272B Dec 12 16:48 \u001b[34m..\u001b[m\u001b[m\r\n",
        "drwxr-xr-x  13 jhamrick  staff   442B Dec 12 16:48 \u001b[34m.git\u001b[m\u001b[m\r\n",
        "-rw-r--r--   1 jhamrick  staff    38B Dec 12 16:48 README.md\r\n",
        "lrwxr-xr-x   1 jhamrick  staff   200B Dec 12 16:48 \u001b[35mbigfile.npy\u001b[m\u001b[m -> .git/annex/objects/z8/G9/SHA256E-s80000080--a71c2242f2043dbf8e284ef98d2950f4e569d1707c319023b6ddf3dfb8078150.npy/SHA256E-s80000080--a71c2242f2043dbf8e284ef98d2950f4e569d1707c319023b6ddf3dfb8078150.npy\r\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "## Deleting files from `git-annex`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Similarly, `git-annex` is paranoid if you try to remove files. If you just remove the symlink, that won't actually delete the file, because its contents are stored in the `.git` directory. Instead, you must use `git annex drop`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd myrepo && git annex drop bigfile.npy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "drop bigfile.npy (unsafe) \r\n",
        "  Could only verify the existence of 0 out of 1 necessary copies\r\n",
        "\r\n",
        "  Rather than dropping this file, try using: git annex move\r\n",
        "\r\n",
        "  (Use --force to override this check, or adjust numcopies.)\r\n",
        "failed\r\n",
        "git-annex: drop: 1 failed\r\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, `git-annex` only knows about one copy of `bigfile.npy`, and therefore knows that if we remove this version of it, we will never be able to recover it. So, it tells use that the drop is \"unsafe\" and won't let us proceed. If we really wanted to get rid of it, we could use `git annex drop --force bigfile.npy` -- but let's not actually do that."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How do you know, in general, where the various copies of a file are? You can use the `git annex whereis` command or the `git annex list` command. `whereis` shows detailed information about each file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd myrepo && git annex whereis"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "whereis bigfile.npy (1 copy) \r\n",
        "  \tc574136a-0a54-4ccb-9f93-2144e4d9e808 -- here (laptop)\r\n",
        "ok\r\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `list` command gives an abbreviated version of the same information, telling you which remotes have which files (deted by an `X`):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd myrepo && git annex list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "here\r\n",
        "|origin\r\n",
        "||web\r\n",
        "|||\r\n",
        "X__ bigfile.npy\r\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "## Storing data in multiple places"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before we can save our data to multiple places, we need to update the remote repository with information about `git-annex`. Since many remotes don't actually support `git-annex` (such as GitHub or Bitbucket), we need to set a few configuration variables to tell `git-annex`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "\n",
      "cd myrepo\n",
      "git config remote.origin.annex-ignore true\n",
      "git config remote.origin.annex-sync true"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This will tell `git-annex` to ignore the remote repository (it won't look for data there), but it *should* sync to the remote repository (i.e., push the `git-annex` branch)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, let's say you have an external hard drive that you want to save copies of your data to. In order to tell `git-annex` to save your data there, we need to create a copy of the repository:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "\n",
      "mkdir /tmp/external\n",
      "cd /tmp/external\n",
      "git clone /tmp/myrepo.git\n",
      "cd myrepo\n",
      "git annex init \"external\"\n",
      "\n",
      "# also configure the remote settings here\n",
      "git config remote.origin.annex-ignore true\n",
      "git config remote.origin.annex-sync true"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "init external ok\n",
        "(Recording state in git...)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Cloning into 'myrepo'...\n",
        "done.\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we need to tell the two repositories about each other:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "\n",
      "# tell the external repository about the laptop repository\n",
      "LOCALPATH=$(pwd)/myrepo\n",
      "cd /tmp/external/myrepo\n",
      "git remote add laptop $LOCALPATH\n",
      "\n",
      "# tell the laptop repository about the external repository\n",
      "cd $LOCALPATH\n",
      "git remote add external /tmp/external/myrepo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that the repositories know about each other, we can copy the content from our local repository to the external repository:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd myrepo && git annex copy --to external"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "copy bigfile.npy (to external...) "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ok\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(Recording state in git...)\r\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And once we've done this, the `whereis` command should show that the data exists both here (the \"laptop\" repository) and in the external repository:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd myrepo && git annex whereis"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "whereis bigfile.npy (2 copies) \r\n",
        "  \t93bea19e-efb1-44a5-97c8-c15caa17929e -- external\r\n",
        "   \tc574136a-0a54-4ccb-9f93-2144e4d9e808 -- here (laptop)\r\n",
        "ok\r\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, if we run the `whereis` command from the external repository, it doesn't know about all the copies of the data. Why?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd /tmp/external/myrepo && git annex whereis"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "whereis bigfile.npy (1 copy) \r\n",
        "  \t93bea19e-efb1-44a5-97c8-c15caa17929e -- here (external)\r\n",
        "ok\r\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The reason has to do with how `git-annex` works. The way that it keeps track of where all the various files are, is with a special branch called `git-annex`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd /tmp/external/myrepo && git branch"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  git-annex\u001b[m\r\n",
        "* \u001b[32mmaster\u001b[m\r\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Whe has happened is that the `git-annex` branch in the external repository is out of date, compared to the `git-annex` branch in the laptop repository. To get it up to date, we run the command `git annex sync`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd /tmp/external/myrepo && git annex sync"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "commit  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ok\r\n",
        "pull laptop \r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "remote: Counting objects: 21, done.\u001b[K\r\n",
        "remote: Compressing objects:   6% (1/15)   \u001b[K\r",
        "remote: Compressing objects:  13% (2/15)   \u001b[K\r",
        "remote: Compressing objects:  20% (3/15)   \u001b[K\r",
        "remote: Compressing objects:  26% (4/15)   \u001b[K\r",
        "remote: Compressing objects:  33% (5/15)   \u001b[K\r",
        "remote: Compressing objects:  40% (6/15)   \u001b[K\r",
        "remote: Compressing objects:  46% (7/15)   \u001b[K\r",
        "remote: Compressing objects:  53% (8/15)   \u001b[K\r",
        "remote: Compressing objects:  60% (9/15)   \u001b[K\r",
        "remote: Compressing objects:  66% (10/15)   \u001b[K\r",
        "remote: Compressing objects:  73% (11/15)   \u001b[K\r",
        "remote: Compressing objects:  80% (12/15)   \u001b[K\r",
        "remote: Compressing objects:  86% (13/15)   \u001b[K\r",
        "remote: Compressing objects:  93% (14/15)   \u001b[K\r",
        "remote: Compressing objects: 100% (15/15)   \u001b[K\r",
        "remote: Compressing objects: 100% (15/15), done.\u001b[K\r\n",
        "remote: Total 20 (delta 2), reused 0 (delta 0)\u001b[K\r\n",
        "Unpacking objects:   5% (1/20)   \r",
        "Unpacking objects:  10% (2/20)   \r",
        "Unpacking objects:  15% (3/20)   \r",
        "Unpacking objects:  20% (4/20)   \r",
        "Unpacking objects:  25% (5/20)   \r",
        "Unpacking objects:  30% (6/20)   \r",
        "Unpacking objects:  35% (7/20)   \r",
        "Unpacking objects:  40% (8/20)   \r",
        "Unpacking objects:  45% (9/20)   \r",
        "Unpacking objects:  50% (10/20)   \r",
        "Unpacking objects:  55% (11/20)   \r",
        "Unpacking objects:  60% (12/20)   \r",
        "Unpacking objects:  65% (13/20)   \r",
        "Unpacking objects:  70% (14/20)   \r",
        "Unpacking objects:  75% (15/20)   \r",
        "Unpacking objects:  80% (16/20)   \r",
        "Unpacking objects:  85% (17/20)   \r",
        "Unpacking objects:  90% (18/20)   \r",
        "Unpacking objects:  95% (19/20)   \r",
        "Unpacking objects: 100% (20/20)   \r",
        "Unpacking objects: 100% (20/20), done.\r\n",
        "From /Users/jhamrick/project/misc/git-annex-tutorial/myrepo\r\n",
        " * [new branch]      git-annex  -> laptop/git-annex\r\n",
        " * [new branch]      master     -> laptop/master\r\n",
        "ok\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(merging laptop/git-annex into git-annex...)\r\n",
        "(Recording state in git...)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "push laptop \r\n",
        "Counting objects: 22, done.\r\n",
        "Delta compression using up to 4 threads.\r\n",
        "Compressing objects:   8% (1/12)   \r",
        "Compressing objects:  16% (2/12)   \r",
        "Compressing objects:  25% (3/12)   \r",
        "Compressing objects:  33% (4/12)   \r",
        "Compressing objects:  41% (5/12)   \r",
        "Compressing objects:  50% (6/12)   \r",
        "Compressing objects:  58% (7/12)   \r",
        "Compressing objects:  66% (8/12)   \r",
        "Compressing objects:  75% (9/12)   \r",
        "Compressing objects:  83% (10/12)   \r",
        "Compressing objects:  91% (11/12)   \r",
        "Compressing objects: 100% (12/12)   \r",
        "Compressing objects: 100% (12/12), done.\r\n",
        "Writing objects:   6% (1/16)   \r",
        "Writing objects:  12% (2/16)   \r",
        "Writing objects:  18% (3/16)   \r",
        "Writing objects:  25% (4/16)   \r",
        "Writing objects:  31% (5/16)   \r",
        "Writing objects:  37% (6/16)   \r",
        "Writing objects:  43% (7/16)   \r",
        "Writing objects:  50% (8/16)   \r",
        "Writing objects:  56% (9/16)   \r",
        "Writing objects:  62% (10/16)   \r",
        "Writing objects:  68% (11/16)   \r",
        "Writing objects:  75% (12/16)   \r",
        "Writing objects:  81% (13/16)   \r",
        "Writing objects:  87% (14/16)   \r",
        "Writing objects:  93% (15/16)   \r",
        "Writing objects: 100% (16/16)   \r",
        "Writing objects: 100% (16/16), 1.29 KiB | 0 bytes/s, done.\r\n",
        "Total 16 (delta 5), reused 0 (delta 0)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "To /Users/jhamrick/project/misc/git-annex-tutorial/myrepo\r\n",
        " * [new branch]      git-annex -> synced/git-annex\r\n",
        " * [new branch]      master -> synced/master\r\n",
        "ok\r\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, if we check `whereis`, it sees that the data is both in the laptop repository and in the external repository:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd /tmp/external/myrepo && git annex whereis"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "whereis bigfile.npy (2 copies) \r\n",
        "  \t93bea19e-efb1-44a5-97c8-c15caa17929e -- here (external)\r\n",
        "   \tc574136a-0a54-4ccb-9f93-2144e4d9e808 -- laptop\r\n",
        "ok\r\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "## Dropping files, revisited"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that our data is in two places, we can try dropping the file from the `laptop` repository:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd myrepo && git annex drop bigfile.npy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(merging synced/git-annex into git-annex...)\r\n",
        "drop bigfile.npy "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ok\r\n",
        "(Recording state in git...)\r\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It works ok, now, because it knows about the other copy of the file in the external repository. Also, if we now check `whereis`, it will tell use that it is only in the external repository:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd myrepo && git annex whereis"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "whereis bigfile.npy (1 copy) \r\n",
        "  \t93bea19e-efb1-44a5-97c8-c15caa17929e -- external\r\n",
        "ok\r\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To get a copy of the file back, we can use the `git annex get` command:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd myrepo && git annex get bigfile.npy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "get bigfile.npy "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(from external...) "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ok\r\n",
        "(Recording state in git...)\r\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "## My workflow"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In practice, there are a few ways that I tend to use `git-annex`. You don't have to follow these, but I'll share them in case you are interested!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Using `rsync` remotes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You don't have to actually check out a separate copy of the repository to copy your data -- and in fact, I usually *don't* want this (because I don't want a separate repository -- I just want a data store). One alternative to cloning the repository is to use an *rsync remote* (see also [the git-annex page on special remotes](http://git-annex.branchable.com/special_remotes/rsync/)):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd myrepo && git annex initremote myrsync type=rsync rsyncurl=/tmp/myrepo-rsync encryption=none"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "initremote myrsync ok\r\n",
        "(Recording state in git...)\r\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd myrepo && git annex copy --to myrsync"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "copy bigfile.npy (checking myrsync...) "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(to myrsync...) \r\n",
        "building file list ... \r\n",
        " 0 files...\r",
        "5 files to consider\r\n",
        "created directory /tmp/myrepo-rsync\r\n",
        "./\r\n",
        "a89/\r\n",
        "a89/274/\r\n",
        "a89/274/SHA256E-s80000080--a71c2242f2043dbf8e284ef98d2950f4e569d1707c319023b6ddf3dfb8078150.npy/\r\n",
        "a89/274/SHA256E-s80000080--a71c2242f2043dbf8e284ef98d2950f4e569d1707c319023b6ddf3dfb8078150.npy/SHA256E-s80000080--a71c2242f2043dbf8e284ef98d2950f4e569d1707c319023b6ddf3dfb8078150.npy\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "       32768   0%    0.00kB/s    0:00:00\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "    80000080 100%  134.03MB/s    0:00:00 (xfer#1, to-check=0/5)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "sent 80010168 bytes  received 66 bytes  160020468.00 bytes/sec\r\n",
        "total size is 80000080  speedup is 1.00\r\n",
        "ok\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(Recording state in git...)\r\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd myrepo && git annex whereis"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "whereis bigfile.npy (3 copies) \r\n",
        "  \t93bea19e-efb1-44a5-97c8-c15caa17929e -- external\r\n",
        "   \tc574136a-0a54-4ccb-9f93-2144e4d9e808 -- here (laptop)\r\n",
        "   \td9360582-4086-4d17-9273-256082e886f0 -- myrsync\r\n",
        "ok\r\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we look at the folder where we initialized this remote, we see that it is not a true git repository -- it is just a folder containing specially named `git-annex` objects:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls -R /tmp/myrepo-rsync"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[34ma89\u001b[m\u001b[m\r\n",
        "\r\n",
        "/tmp/myrepo-rsync/a89:\r\n",
        "\u001b[34m274\u001b[m\u001b[m\r\n",
        "\r\n",
        "/tmp/myrepo-rsync/a89/274:\r\n",
        "\u001b[34mSHA256E-s80000080--a71c2242f2043dbf8e284ef98d2950f4e569d1707c319023b6ddf3dfb8078150.npy\u001b[m\u001b[m\r\n",
        "\r\n",
        "/tmp/myrepo-rsync/a89/274/SHA256E-s80000080--a71c2242f2043dbf8e284ef98d2950f4e569d1707c319023b6ddf3dfb8078150.npy:\r\n",
        "SHA256E-s80000080--a71c2242f2043dbf8e284ef98d2950f4e569d1707c319023b6ddf3dfb8078150.npy\r\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Changing the number of copies"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I usually like to have more than one copy of my data lying around, for a few things. First, it's possible that the one place that it is stored gets lost: the hard drive dies, the computer gets stolen, etc. Additionally, bit rot is a real thing -- sometimes a bit gets randomly flipped on your disk, which can cause your files to become corrupted! So, to ensure that there are always enough copies of my data, I usually tell `git-annex` to keep track of at least 2, usually 3 copies:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd myrepo && git annex numcopies 3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "numcopies 3 ok\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(Recording state in git...)\r\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that now, if I tried to drop the file, it wouldn't work because I've told `git-annex` that I always want three copies:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd myrepo && git annex drop bigfile.npy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "drop bigfile.npy (checking myrsync...) "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(unsafe) \r\n",
        "  Could only verify the existence of 2 out of 3 necessary copies\r\n",
        "\r\n",
        "  Rather than dropping this file, try using: git annex move\r\n",
        "\r\n",
        "  (Note that these git remotes have annex-ignore set: origin)\r\n",
        "\r\n",
        "  (Use --force to override this check, or adjust numcopies.)\r\n",
        "failed\r\n",
        "git-annex: drop: 1 failed\r\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Keeping track of \"unused\" data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Recall that earlier we made a change to `bigfile.npy`. What happened to the original version of the file? `git-annex` still keeps track of it, but now the file is *unused*. We can see all the unused files with `git annex unused`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd myrepo && git annex unused"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "unused . (checking for unused data...) "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(checking master...) \r\n",
        "  Some annexed data is no longer used by any files:\r\n",
        "    NUMBER  KEY\r\n",
        "    1       SHA256E-s80000080--68df193c08a87b39d02f5fb271557a36dd1a9af7b9a7f1d0bd0011e7ec253ebd.npy\r\n",
        "  (To see where data was previously used, try: git log --stat -S'KEY')\r\n",
        "  \r\n",
        "  To remove unwanted data: git-annex dropunused NUMBER\r\n",
        "  \r\n",
        "ok\r\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I usually err on the side of caution and keep all the unused data. However, it can add up in size, so I will usually copy it to my remotes:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "\n",
      "cd myrepo\n",
      "git annex copy --unused --to external\n",
      "git annex move --unused --to myrsync # move, rather than copy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "copy SHA256E-s80000080--68df193c08a87b39d02f5fb271557a36dd1a9af7b9a7f1d0bd0011e7ec253ebd.npy (to external...) ok\n",
        "(Recording state in git...)\n",
        "move SHA256E-s80000080--68df193c08a87b39d02f5fb271557a36dd1a9af7b9a7f1d0bd0011e7ec253ebd.npy (checking myrsync...) (to myrsync...) \n",
        "building file list ... \n",
        " 0 files...\r",
        "5 files to consider\n",
        "53c/\n",
        "53c/c0c/\n",
        "53c/c0c/SHA256E-s80000080--68df193c08a87b39d02f5fb271557a36dd1a9af7b9a7f1d0bd0011e7ec253ebd.npy/\n",
        "53c/c0c/SHA256E-s80000080--68df193c08a87b39d02f5fb271557a36dd1a9af7b9a7f1d0bd0011e7ec253ebd.npy/SHA256E-s80000080--68df193c08a87b39d02f5fb271557a36dd1a9af7b9a7f1d0bd0011e7ec253ebd.npy\n",
        "       32768   0%    0.00kB/s    0:00:00\r",
        "    80000080 100%  115.90MB/s    0:00:00 (xfer#1, to-check=0/5)\n",
        "\n",
        "sent 80010162 bytes  received 60 bytes  53340148.00 bytes/sec\n",
        "total size is 80000080  speedup is 1.00\n",
        "ok\n",
        "(Recording state in git...)\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we'll see that there's no unused data in the \"laptop\" repository:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd myrepo && git annex unused"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "unused . (checking for unused data...) ok\r\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Keep everything in `git-annex`!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I keep a *ton* of stuff in `git-annex`. For example, here's all the stuff that I have in one of my repositories (this command won't work for you, unless you happen to have a copy of my repository!):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd ~/project/research/mass-inference && git annex list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "here\r\n",
        "|origin\r\n",
        "||external\r\n",
        "|||lovelace\r\n",
        "||||twilight-sparkle\r\n",
        "|||||web\r\n",
        "||||||\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "X_XXX_ analysis/figures/forklift.jpg\r\n",
        "X_XXX_ data/human-raw/mass_inference-G/eventdata.csv\r\n",
        "X_XXX_ data/human-raw/mass_inference-G/questiondata.csv\r\n",
        "X_XXX_ data/human-raw/mass_inference-G/trialdata.csv\r\n",
        "X_XXX_ data/human-raw/mass_inference-H/eventdata.csv\r\n",
        "X_XXX_ data/human-raw/mass_inference-H/questiondata.csv\r\n",
        "X_XXX_ data/human-raw/mass_inference-H/trialdata.csv\r\n",
        "X_XXX_ data/human-raw/mass_inference-I/eventdata.csv\r\n",
        "X_XXX_ data/human-raw/mass_inference-I/questiondata.csv\r\n",
        "X_XXX_ data/human-raw/mass_inference-I/trialdata.csv\r\n",
        "__XXX_ data/human/direction_1.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/direction_2.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/direction_discrete_halves.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/direction_discrete_quadrants.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/direction_scatter.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/mass_billiards.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/mass_direction_1.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/mass_direction_2.dpkg/experiment.csv\r\n",
        "X_XXX_ data/human/mass_inference-G.dpkg/events.csv\r\n",
        "X_XXX_ data/human/mass_inference-G.dpkg/experiment.csv\r\n",
        "X_XXX_ data/human/mass_inference-G.dpkg/participants.csv\r\n",
        "X_XXX_ data/human/mass_inference-H.dpkg/events.csv\r\n",
        "X_XXX_ data/human/mass_inference-H.dpkg/experiment.csv\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "X_XXX_ data/human/mass_inference-H.dpkg/participants.csv\r\n",
        "X_XXX_ data/human/mass_inference-I.dpkg/events.csv\r\n",
        "X_XXX_ data/human/mass_inference-I.dpkg/experiment.csv\r\n",
        "X_XXX_ data/human/mass_inference-I.dpkg/participants.csv\r\n",
        "X_XXX_ data/human/mass_inference-merged.dpkg/events.csv\r\n",
        "X_XXX_ data/human/mass_inference-merged.dpkg/experiment.csv\r\n",
        "X_XXX_ data/human/mass_inference-merged.dpkg/participants.csv\r\n",
        "__XXX_ data/human/mass_learning_A.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/mass_learning_A.dpkg/turk.csv\r\n",
        "__XXX_ data/human/mass_learning_B.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/mass_learning_B.dpkg/turk.csv\r\n",
        "__XXX_ data/human/mass_learning_CD.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/mass_learning_CD.dpkg/turk.csv\r\n",
        "__XXX_ data/human/mass_learning_E.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/mass_learning_E.dpkg/turk.csv\r\n",
        "__XXX_ data/human/mass_oneshot_F.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/mass_oneshot_F.dpkg/turk.csv\r\n",
        "__XXX_ data/human/mass_stability_1.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/mass_stability_2.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/scatter.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/scatter_discrete.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/scatter_sameheight.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/stability.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/stability_2afc.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/stability_alternating_spin.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/stability_fmri.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/stability_nfb.dpkg/experiment.csv\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "__XXX_ data/human/stability_no_spin.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/stability_no_spin_nfb.dpkg/experiment.csv\r\n",
        "__XXX_ data/human/stability_sameheight.dpkg/experiment.csv\r\n",
        "X_XXX_ data/human/workers.db\r\n",
        "__XXX_ data/model-raw/mass_all.dpkg/forces.npy\r\n",
        "__XXX_ data/model-raw/mass_all.dpkg/simulations.npy\r\n",
        "__XXX_ data/model-raw/mass_all_ipe.dpkg/forces.npy\r\n",
        "__XXX_ data/model-raw/mass_all_ipe.dpkg/noises.npy\r\n",
        "__XXX_ data/model-raw/mass_all_ipe.dpkg/simulations.npy\r\n",
        "__XXX_ data/model-raw/mass_all_truth.dpkg/forces.npy\r\n",
        "__XXX_ data/model-raw/mass_all_truth.dpkg/noises.npy\r\n",
        "__XXX_ data/model-raw/mass_all_truth.dpkg/simulations.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-G-a_ipe.dpkg/forces.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-G-a_ipe.dpkg/noises.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-G-a_ipe.dpkg/simulations.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-G-a_truth.dpkg/forces.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-G-a_truth.dpkg/noises.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-G-a_truth.dpkg/simulations.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-G-b_ipe.dpkg/forces.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-G-b_ipe.dpkg/noises.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-G-b_ipe.dpkg/simulations.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-G-b_truth.dpkg/forces.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-G-b_truth.dpkg/noises.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-G-b_truth.dpkg/simulations.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-I-a_ipe.dpkg/forces.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-I-a_ipe.dpkg/noises.npy\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "X_XXX_ data/model-raw/mass_inference-I-a_ipe.dpkg/simulations.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-I-a_truth.dpkg/forces.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-I-a_truth.dpkg/noises.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-I-a_truth.dpkg/simulations.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-I-b_ipe.dpkg/forces.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-I-b_ipe.dpkg/noises.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-I-b_ipe.dpkg/simulations.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-I-b_truth.dpkg/forces.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-I-b_truth.dpkg/noises.npy\r\n",
        "X_XXX_ data/model-raw/mass_inference-I-b_truth.dpkg/simulations.npy\r\n",
        "__XXX_ data/model-raw/mass_learning.dpkg/forces.npy\r\n",
        "__XXX_ data/model-raw/mass_learning.dpkg/simulations.npy\r\n",
        "__XXX_ data/model-raw/mass_learning_ipe.dpkg/forces.npy\r\n",
        "__XXX_ data/model-raw/mass_learning_ipe.dpkg/noises.npy\r\n",
        "__XXX_ data/model-raw/mass_learning_ipe.dpkg/simulations.npy\r\n",
        "__XXX_ data/model-raw/mass_learning_truth.dpkg/forces.npy\r\n",
        "__XXX_ data/model-raw/mass_learning_truth.dpkg/noises.npy\r\n",
        "__XXX_ data/model-raw/mass_learning_truth.dpkg/simulations.npy\r\n",
        "__XXX_ data/model-raw/mass_prediction_direction.dpkg/forces.npy\r\n",
        "__XXX_ data/model-raw/mass_prediction_direction.dpkg/simulations.npy\r\n",
        "__XXX_ data/model-raw/mass_prediction_stability.dpkg/forces.npy\r\n",
        "__XXX_ data/model-raw/mass_prediction_stability.dpkg/simulations.npy\r\n",
        "__XXX_ data/model-raw/mass_prediction_stability_truth.dpkg/forces.npy\r\n",
        "__XXX_ data/model-raw/mass_prediction_stability_truth.dpkg/noises.npy\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "__XXX_ data/model-raw/mass_prediction_stability_truth.dpkg/simulations.npy\r\n",
        "__XXX_ data/model-raw/stability_original.dpkg/forces.npy\r\n",
        "__XXX_ data/model-raw/stability_original.dpkg/simulations.npy\r\n",
        "__XXX_ data/model-raw/stability_original_ipe.dpkg/forces.npy\r\n",
        "__XXX_ data/model-raw/stability_original_ipe.dpkg/noises.npy\r\n",
        "__XXX_ data/model-raw/stability_original_ipe.dpkg/simulations.npy\r\n",
        "__XXX_ data/model-raw/stability_original_truth.dpkg/forces.npy\r\n",
        "__XXX_ data/model-raw/stability_original_truth.dpkg/noises.npy\r\n",
        "__XXX_ data/model-raw/stability_original_truth.dpkg/simulations.npy\r\n",
        "__XXX_ data/model-raw/stability_sameheight.dpkg/forces.npy\r\n",
        "__XXX_ data/model-raw/stability_sameheight.dpkg/simulations.npy\r\n",
        "__XXX_ data/model-raw/stability_sameheight_ipe.dpkg/forces.npy\r\n",
        "__XXX_ data/model-raw/stability_sameheight_ipe.dpkg/noises.npy\r\n",
        "__XXX_ data/model-raw/stability_sameheight_ipe.dpkg/simulations.npy\r\n",
        "__XXX_ data/model-raw/stability_sameheight_truth.dpkg/forces.npy\r\n",
        "__XXX_ data/model-raw/stability_sameheight_truth.dpkg/noises.npy\r\n",
        "__XXX_ data/model-raw/stability_sameheight_truth.dpkg/simulations.npy\r\n",
        "__XXX_ data/model-raw/stability_unstable.dpkg/forces.npy\r\n",
        "__XXX_ data/model-raw/stability_unstable.dpkg/simulations.npy\r\n",
        "__XXX_ data/model-raw/stability_unstable_sameheight.dpkg/forces.npy\r\n",
        "__XXX_ data/model-raw/stability_unstable_sameheight.dpkg/simulations.npy\r\n",
        "X_XXX_ data/model/mass_all_ipe_fall.dpkg/model.csv\r\n",
        "X_XXX_ data/model/mass_all_truth_fall.dpkg/model.csv\r\n",
        "X_XXX_ data/model/mass_inference-G-a_ipe_fall.dpkg/model.csv\r\n",
        "X_XXX_ data/model/mass_inference-G-a_truth_fall.dpkg/model.csv\r\n",
        "X_XXX_ data/model/mass_inference-G-b_ipe_fall.dpkg/model.csv\r\n",
        "X_XXX_ data/model/mass_inference-G-b_truth_fall.dpkg/model.csv\r\n",
        "X_XXX_ data/model/mass_inference-I-a_ipe_fall.dpkg/model.csv\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "X_XXX_ data/model/mass_inference-I-a_truth_fall.dpkg/model.csv\r\n",
        "X_XXX_ data/model/mass_inference-I-b_ipe_fall.dpkg/model.csv\r\n",
        "X_XXX_ data/model/mass_inference-I-b_truth_fall.dpkg/model.csv\r\n",
        "X_XXX_ data/model/mass_learning_ipe_fall.dpkg/model.csv\r\n",
        "X_XXX_ data/model/mass_learning_truth_fall.dpkg/model.csv\r\n",
        "X_XXX_ data/model/mass_prediction_stability_truth_fall.dpkg/model.csv\r\n",
        "X_XXX_ data/model/stability_original_ipe_fall.dpkg/model.csv\r\n",
        "X_XXX_ data/model/stability_original_truth_fall.dpkg/model.csv\r\n",
        "X_XXX_ data/model/stability_sameheight_ipe_fall.dpkg/model.csv\r\n",
        "X_XXX_ data/model/stability_sameheight_truth_fall.dpkg/model.csv\r\n",
        "__XXX_ data/old/old-cogphysics-human-raw-reorganized.zip\r\n",
        "__XXX_ data/old/old-cogphysics-human-raw.zip\r\n",
        "__XXX_ data/old/old-cogphysics-model-raw/s_tower_mass41D-all.zip\r\n",
        "__XXX_ data/old/old-cogphysics-model-raw/s_tower_mass41S-all.zip\r\n",
        "__XXX_ data/old/old-cogphysics-model-raw/s_tower_massD-all.zip\r\n",
        "__XXX_ data/old/old-cogphysics-model-raw/s_tower_massS-all.zip\r\n",
        "__XXX_ data/old/old-cogphysics-model-raw/s_tower_mass_all-all.zip\r\n",
        "__XXX_ data/old/old-cogphysics-model-raw/s_tower_mass_learningS-all.zip\r\n",
        "__XXX_ data/old/old-cogphysics-model-raw/s_tower_original-all.zip\r\n",
        "__XXX_ data/old/old-cogphysics-model-raw/s_tower_originalSH-all.zip\r\n",
        "__XXX_ data/old/old-cogphysics-model-raw/s_tower_unstable-all.zip\r\n",
        "__XXX_ data/old/old-cogphysics-model-raw/s_tower_unstableSH-all.zip\r\n",
        "__XXX_ data/old/old-turk-batch-results.zip\r\n",
        "__XXX_ data/sim-raw/mass_all/ipe.tar.gz\r\n",
        "__XXX_ data/sim-raw/mass_all/truth.tar.gz\r\n",
        "X_XXX_ data/sim-raw/mass_inference-G-a/ipe.tar.gz\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "X_XXX_ data/sim-raw/mass_inference-G-a/truth.tar.gz\r\n",
        "X_XXX_ data/sim-raw/mass_inference-G-b/ipe.tar.gz\r\n",
        "X_XXX_ data/sim-raw/mass_inference-G-b/truth.tar.gz\r\n",
        "__XXX_ data/sim-raw/mass_inference-I-a/ipe.tar.gz\r\n",
        "__XXX_ data/sim-raw/mass_inference-I-a/truth.tar.gz\r\n",
        "__XXX_ data/sim-raw/mass_inference-I-b/ipe.tar.gz\r\n",
        "__XXX_ data/sim-raw/mass_inference-I-b/truth.tar.gz\r\n",
        "__XXX_ data/sim-raw/mass_learning/ipe.tar.gz\r\n",
        "__XXX_ data/sim-raw/mass_learning/truth.tar.gz\r\n",
        "__XXX_ data/sim-raw/mass_prediction_stability/truth.tar.gz\r\n",
        "__XXX_ data/sim-raw/stability_original/ipe.tar.gz\r\n",
        "__XXX_ data/sim-raw/stability_original/truth.tar.gz\r\n",
        "__XXX_ data/sim-raw/stability_sameheight/ipe.tar.gz\r\n",
        "__XXX_ data/sim-raw/stability_sameheight/truth.tar.gz\r\n",
        "__XXX_ experiment/old-versions/PhysicsExperiment-A.tar.gz\r\n",
        "__XXX_ experiment/old-versions/PhysicsExperiment-B.tar.gz\r\n",
        "__XXX_ experiment/old-versions/PhysicsExperiment-CD.tar.gz\r\n",
        "__XXX_ experiment/old-versions/PhysicsExperiment-E.tar.gz\r\n",
        "__XXX_ experiment/old-versions/PhysicsExperiment-F.tar.gz\r\n",
        "__XXX_ experiment/old-versions/PhysicsExperiment-G-2.tar.gz\r\n",
        "__XXX_ experiment/old-versions/PhysicsExperiment-G.tar.gz\r\n",
        "__XXX_ experiment/old-versions/PhysicsExperiment-H.tar.gz\r\n",
        "X_XXX_ experiment/old-versions/PhysicsExperiment-I.tar.gz\r\n",
        "X_XXX_ experiment/remote-config.txt\r\n",
        "X_XXX_ resources/blend/block.blend\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "X_XXX_ resources/blend/block2.blend\r\n",
        "X_XXX_ resources/blend/cylinderX.blend\r\n",
        "X_XXX_ resources/blend/cylinderY.blend\r\n",
        "X_XXX_ resources/blend/cylinderZ.blend\r\n",
        "X_XXX_ resources/blend/red_block.blend\r\n",
        "X_XXX_ resources/blend/stone_block.blend\r\n",
        "X_XXX_ resources/blend/tower.blend\r\n",
        "X_XXX_ resources/blend/wood_block.blend\r\n",
        "X_XXX_ resources/blend/wood_floor.blend\r\n",
        "X_XXX_ resources/blend/yellow_block.blend\r\n",
        "X_XXX_ resources/egg/block.egg\r\n",
        "X_XXX_ resources/egg/cylinderX.egg\r\n",
        "X_XXX_ resources/egg/cylinderY.egg\r\n",
        "X_XXX_ resources/egg/cylinderZ.egg\r\n",
        "X_XXX_ resources/egg/red_block.egg\r\n",
        "X_XXX_ resources/egg/stone_block.egg\r\n",
        "X_XXX_ resources/egg/wood_block.egg\r\n",
        "X_XXX_ resources/egg/wood_floor.egg\r\n",
        "X_XXX_ resources/egg/yellow_block.egg\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-G/nfb-0.1-cb0/experimentB.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-G/nfb-0.1-cb1/experimentB.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-G/nfb-10-cb0/experimentB.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-G/nfb-10-cb1/experimentB.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-G/shared/pretest.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-G/shared/stable_example.json\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "X_XXX_ resources/render-scripts/mass_inference-G/shared/unstable_example.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-G/vfb-0.1-cb0/experimentA.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-G/vfb-0.1-cb0/experimentC.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-G/vfb-0.1-cb0/mass_example.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-G/vfb-0.1-cb1/experimentA.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-G/vfb-0.1-cb1/experimentC.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-G/vfb-0.1-cb1/mass_example.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-G/vfb-10-cb0/experimentA.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-G/vfb-10-cb0/experimentC.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-G/vfb-10-cb0/mass_example.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-G/vfb-10-cb1/experimentA.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-G/vfb-10-cb1/experimentC.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-G/vfb-10-cb1/mass_example.json\r\n",
        "__XXX_ resources/render-scripts/mass_inference-H/nfb-0.1-cb0/experimentB.json\r\n",
        "__XXX_ resources/render-scripts/mass_inference-H/nfb-0.1-cb1/experimentB.json\r\n",
        "__XXX_ resources/render-scripts/mass_inference-H/nfb-10-cb0/experimentB.json\r\n",
        "__XXX_ resources/render-scripts/mass_inference-H/nfb-10-cb1/experimentB.json\r\n",
        "__XXX_ resources/render-scripts/mass_inference-H/shared/pretest.json\r\n",
        "__XXX_ resources/render-scripts/mass_inference-H/shared/stable_example.json\r\n",
        "__XXX_ resources/render-scripts/mass_inference-H/shared/unstable_example.json\r\n",
        "__XXX_ resources/render-scripts/mass_inference-H/vfb-0.1-cb0/experimentA.json\r\n",
        "__XXX_ resources/render-scripts/mass_inference-H/vfb-0.1-cb0/experimentC.json\r\n",
        "__XXX_ resources/render-scripts/mass_inference-H/vfb-0.1-cb0/mass_example.json\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "__XXX_ resources/render-scripts/mass_inference-H/vfb-0.1-cb1/experimentA.json\r\n",
        "__XXX_ resources/render-scripts/mass_inference-H/vfb-0.1-cb1/experimentC.json\r\n",
        "__XXX_ resources/render-scripts/mass_inference-H/vfb-0.1-cb1/mass_example.json\r\n",
        "__XXX_ resources/render-scripts/mass_inference-H/vfb-10-cb0/experimentA.json\r\n",
        "__XXX_ resources/render-scripts/mass_inference-H/vfb-10-cb0/experimentC.json\r\n",
        "__XXX_ resources/render-scripts/mass_inference-H/vfb-10-cb0/mass_example.json\r\n",
        "__XXX_ resources/render-scripts/mass_inference-H/vfb-10-cb1/experimentA.json\r\n",
        "__XXX_ resources/render-scripts/mass_inference-H/vfb-10-cb1/experimentC.json\r\n",
        "__XXX_ resources/render-scripts/mass_inference-H/vfb-10-cb1/mass_example.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-I/shared/pretest.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-I/shared/stable_example.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-I/shared/unstable_example.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-I/vfb-0.1-cb0/experimentA.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-I/vfb-0.1-cb0/experimentB.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-I/vfb-0.1-cb0/mass_example.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-I/vfb-0.1-cb1/experimentA.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-I/vfb-0.1-cb1/experimentB.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-I/vfb-0.1-cb1/mass_example.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-I/vfb-10-cb0/experimentA.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-I/vfb-10-cb0/experimentB.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-I/vfb-10-cb0/mass_example.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-I/vfb-10-cb1/experimentA.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-I/vfb-10-cb1/experimentB.json\r\n",
        "X_XXX_ resources/render-scripts/mass_inference-I/vfb-10-cb1/mass_example.json\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "X_XXX_ resources/render/mass_inference-G.tar.gz\r\n",
        "__XXX_ resources/render/mass_inference-H.tar.gz\r\n",
        "X_XXX_ resources/render/mass_inference-I.tar.gz\r\n",
        "__XXX_ resources/render/mass_learning-A.zip\r\n",
        "__XXX_ resources/render/mass_learning-B.zip\r\n",
        "__XXX_ resources/render/mass_learning-CD.zip\r\n",
        "__XXX_ resources/render/mass_learning-E.zip\r\n",
        "__XXX_ resources/sim-scripts/mass_all/ipe/force.npy\r\n",
        "__XXX_ resources/sim-scripts/mass_all/ipe/noise.npy\r\n",
        "__XXX_ resources/sim-scripts/mass_all/ipe/script.json\r\n",
        "__XXX_ resources/sim-scripts/mass_all/truth/force.npy\r\n",
        "__XXX_ resources/sim-scripts/mass_all/truth/noise.npy\r\n",
        "__XXX_ resources/sim-scripts/mass_all/truth/script.json\r\n",
        "X_XXX_ resources/sim-scripts/mass_inference-G-a/ipe/force.npy\r\n",
        "X_XXX_ resources/sim-scripts/mass_inference-G-a/ipe/noise.npy\r\n",
        "X_XXX_ resources/sim-scripts/mass_inference-G-a/ipe/script.json\r\n",
        "X_XXX_ resources/sim-scripts/mass_inference-G-a/truth/force.npy\r\n",
        "X_XXX_ resources/sim-scripts/mass_inference-G-a/truth/noise.npy\r\n",
        "X_XXX_ resources/sim-scripts/mass_inference-G-a/truth/script.json\r\n",
        "X_XXX_ resources/sim-scripts/mass_inference-G-b/ipe/force.npy\r\n",
        "X_XXX_ resources/sim-scripts/mass_inference-G-b/ipe/noise.npy\r\n",
        "X_XXX_ resources/sim-scripts/mass_inference-G-b/ipe/script.json\r\n",
        "X_XXX_ resources/sim-scripts/mass_inference-G-b/truth/force.npy\r\n",
        "X_XXX_ resources/sim-scripts/mass_inference-G-b/truth/noise.npy\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "X_XXX_ resources/sim-scripts/mass_inference-G-b/truth/script.json\r\n",
        "X_XXX_ resources/sim-scripts/mass_inference-I-a/ipe/force.npy\r\n",
        "X_XXX_ resources/sim-scripts/mass_inference-I-a/ipe/noise.npy\r\n",
        "__XXX_ resources/sim-scripts/mass_inference-I-a/ipe/script.json\r\n",
        "X_XXX_ resources/sim-scripts/mass_inference-I-a/truth/force.npy\r\n",
        "X_XXX_ resources/sim-scripts/mass_inference-I-a/truth/noise.npy\r\n",
        "X_XXX_ resources/sim-scripts/mass_inference-I-a/truth/script.json\r\n",
        "X_XXX_ resources/sim-scripts/mass_inference-I-b/ipe/force.npy\r\n",
        "X_XXX_ resources/sim-scripts/mass_inference-I-b/ipe/noise.npy\r\n",
        "__XXX_ resources/sim-scripts/mass_inference-I-b/ipe/script.json\r\n",
        "X_XXX_ resources/sim-scripts/mass_inference-I-b/truth/force.npy\r\n",
        "X_XXX_ resources/sim-scripts/mass_inference-I-b/truth/noise.npy\r\n",
        "__XXX_ resources/sim-scripts/mass_inference-I-b/truth/script.json\r\n",
        "__XXX_ resources/sim-scripts/mass_learning/ipe/force.npy\r\n",
        "__XXX_ resources/sim-scripts/mass_learning/ipe/noise.npy\r\n",
        "__XXX_ resources/sim-scripts/mass_learning/ipe/script.json\r\n",
        "__XXX_ resources/sim-scripts/mass_learning/truth/force.npy\r\n",
        "__XXX_ resources/sim-scripts/mass_learning/truth/noise.npy\r\n",
        "__XXX_ resources/sim-scripts/mass_learning/truth/script.json\r\n",
        "__XXX_ resources/sim-scripts/mass_prediction_stability/ipe/force.npy\r\n",
        "__XXX_ resources/sim-scripts/mass_prediction_stability/ipe/noise.npy\r\n",
        "__XXX_ resources/sim-scripts/mass_prediction_stability/ipe/script.json\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "__XXX_ resources/sim-scripts/mass_prediction_stability/truth/force.npy\r\n",
        "__XXX_ resources/sim-scripts/mass_prediction_stability/truth/noise.npy\r\n",
        "__XXX_ resources/sim-scripts/mass_prediction_stability/truth/script.json\r\n",
        "__XXX_ resources/sim-scripts/stability_original/ipe/force.npy\r\n",
        "__XXX_ resources/sim-scripts/stability_original/ipe/noise.npy\r\n",
        "__XXX_ resources/sim-scripts/stability_original/ipe/script.json\r\n",
        "__XXX_ resources/sim-scripts/stability_original/truth/force.npy\r\n",
        "__XXX_ resources/sim-scripts/stability_original/truth/noise.npy\r\n",
        "__XXX_ resources/sim-scripts/stability_original/truth/script.json\r\n",
        "__XXX_ resources/sim-scripts/stability_sameheight/ipe/force.npy\r\n",
        "__XXX_ resources/sim-scripts/stability_sameheight/ipe/noise.npy\r\n",
        "__XXX_ resources/sim-scripts/stability_sameheight/ipe/script.json\r\n",
        "__XXX_ resources/sim-scripts/stability_sameheight/truth/force.npy\r\n",
        "__XXX_ resources/sim-scripts/stability_sameheight/truth/noise.npy\r\n",
        "__XXX_ resources/sim-scripts/stability_sameheight/truth/script.json\r\n",
        "X_XXX_ resources/sso/mass-all.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-example.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-inference-G-a.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-inference-G-b.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-inference-H-a.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-inference-H-b.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-inference-I-a.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-inference-I-b.tar.gz\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "X_XXX_ resources/sso/mass-inference-example-G.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-inference-example-H.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-inference-example-I.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-inference-stable-example-G.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-inference-stable-example-H.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-inference-stable-example-I.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-inference-training-G.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-inference-training-H.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-inference-training-I.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-inference-unstable-example-G.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-inference-unstable-example-H.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-inference-unstable-example-I.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-learning-training.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-learning.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-oneshot-F.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-oneshot-example-F.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-oneshot-training-F.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-prediction-direction.tar.gz\r\n",
        "X_XXX_ resources/sso/mass-prediction-stability.tar.gz\r\n",
        "X_XXX_ resources/sso/metadata.db\r\n",
        "X_XXX_ resources/sso/stability-all.tar.gz\r\n",
        "X_XXX_ resources/sso/stability-example-stable-F.tar.gz\r\n",
        "X_XXX_ resources/sso/stability-example-stable.tar.gz\r\n",
        "X_XXX_ resources/sso/stability-example-unstable-F.tar.gz\r\n",
        "X_XXX_ resources/sso/stability-example-unstable.tar.gz\r\n",
        "X_XXX_ resources/sso/stability-original.tar.gz\r\n",
        "X_XXX_ resources/sso/stability-sameheight.tar.gz\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "X_XXX_ resources/sso/stability-unstable-sameheight.tar.gz\r\n",
        "X_XXX_ resources/sso/stability-unstable.tar.gz\r\n",
        "X_XXX_ resources/textures/Block_diffuse.png\r\n",
        "X_XXX_ resources/textures/Block_gloss.png\r\n",
        "X_XXX_ resources/textures/ROTARY SAPELE.jpg\r\n",
        "X_XXX_ resources/textures/Red-block_diffuse.png\r\n",
        "X_XXX_ resources/textures/Red-block_gloss.png\r\n",
        "X_XXX_ resources/textures/Wood_floor_diffuse.png\r\n",
        "X_XXX_ resources/textures/Wood_floor_gloss.png\r\n",
        "X_XXX_ resources/textures/Yellow-block_diffuse.png\r\n",
        "X_XXX_ resources/textures/Yellow-block_gloss.png\r\n",
        "X_XXX_ resources/textures/granite-grayscale.jpg\r\n",
        "X_XXX_ resources/textures/noise.rgb\r\n",
        "X_XXX_ resources/textures/noisy-grayscale.jpg\r\n",
        "X_XXX_ resources/textures/stripes.png\r\n",
        "X_XXX_ resources/textures/wood_tile_polar.png\r\n",
        "X_XXX_ resources/textures/wood_tile_polar_desaturated.png\r\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Most of these files aren't very large, but they all fall into one of the following categories:\n",
      "\n",
      "1. Binary file\n",
      "2. Contains sensitive information\n",
      "3. Diffs poorly (e.g., CSV files, single-line JSON files)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}